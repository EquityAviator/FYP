import {
  CheckCircleOutlined,
  DeleteOutlined,
  DownloadOutlined,
  EditOutlined,
  EyeOutlined,
  FileTextOutlined,
  PlayCircleOutlined,
  WarningOutlined,
} from '@ant-design/icons';
import {
  AIActionType,
  type AIArgs,
  callAIWithObjectResponse,
} from '@darkpatternhunter/core/ai-model';
import type { IModelConfig } from '@darkpatternhunter/shared/env';
import { getDebug } from '@darkpatternhunter/shared/logger';
import {
  Alert,
  Button,
  Card,
  Col,
  Empty,
  Image,
  List,
  Modal,
  Progress,
  Row,
  Select,
  Space,
  Spin,
  Statistic,
  Tag,
  Typography,
  message,
} from 'antd';
import dayjs from 'dayjs';
import { useCallback, useEffect, useState } from 'react';
import { useGlobalAIConfig } from '../../hooks/useGlobalAIConfig';
import { getAIConfig, getActiveModelConfig } from '../../utils/aiConfig';
import { drawBboxesOnImage } from '../../utils/bboxOverlay';
import {
  exportAnnotatedImages,
  exportAsCOCO,
  exportAsYOLO,
} from '../../utils/cocoYoloExport';
import {
  type DarkPattern,
  type DatasetEntry,
  clearDatasetEntries,
  deleteDatasetEntry,
  exportDatasetAsBundleZip,
  exportDatasetAsJSON,
  exportForUITarsFineTuning,
  exportTextDatasetAsJSONL,
  getDatasetEntries,
  storeDatasetEntry,
} from '../../utils/datasetDB';
import { cropImageFromBbox } from '../../utils/imageCrop';
import {
  getSiteName,
  isPakistaniEcommerceSite,
  validateUrl,
} from '../../utils/pakistaniSites';
import BboxEditor from './BboxEditor';
import './index.less';

const { Text, Paragraph } = Typography;
const debug = getDebug('dataset-collection');

// Enhanced dark pattern detection prompt for Pakistani e-commerce
const DARK_PATTERN_PROMPT = `You are a Dark Pattern Detection AI expert specializing in Pakistani e-commerce websites.

Given a webpage screenshot and DOM, identify all dark patterns present on the page.

Use this taxonomy (aligns with the provided CSV list):
- Nagging: repetitive popups/banners; Dead End/Roach Motel (hard to exit/only forward)
- Price Comparison Prevention: hiding/obfuscating comparison info
- Disguised Ad / Bait & Switch: ads styled as content
- Reference Pricing: "was/now", strikethrough anchor price
- False Hierarchy: primary CTA overly dominant vs secondary/back
- Bundling / Auto-add / Bad Defaults: pre-selected add-ons/options
- Pressured Selling / FOMO / Urgency: urgent language, timers
- Scarcity & Popularity: low stock/high demand/viewing now
- Hard To Close: tiny/hidden/misplaced close on overlays
- Trick Questions / Confirmshaming: shaming/ambiguous opt-out
- Hidden Information: fees/terms in fine print or revealed late
- Infinite Scrolling: endless feed without clear end/pagination
- Forced Ads: watch ads/pay to avoid; Autoplay media

Language coverage: English + Urdu (Perso-Arabic) + Roman Urdu.
Examples (Roman Urdu): "Jaldi karein", "Aakhri mauqa", "Fori khareedain", "Sirf X baaqi", "Kam stock", "Aur dekhein", "Mansookh karein".

Evidence requirements:
- Provide exact text/element evidence; if visual, describe element (timer, badge, close button position/size).
- Only include patterns with confidence > 0.7.
- Prefer concise descriptions and precise locations (e.g., "product card badge", "checkout summary fee line", "overlay top-right close button").

BOUNDING BOX GUIDANCE:
- If the pattern is visual (e.g., a countdown timer, a banner, a button), provide bounding box coordinates [x, y, width, height] in pixels.
- If the pattern is purely textual or conceptual (e.g., hidden terms in a long paragraph, or general site structure like infinite scroll), providing a bounding box is OPTIONAL. You can omit the "bbox" field or set it to null.
- DO NOT invent bounding boxes if you are unsure.
- x: left edge position in pixels (0 = leftmost)
- y: top edge position in pixels (0 = topmost)
- width: width of the element in pixels
- height: height of the element in pixels

OUTPUT REQUIREMENT: Return ONLY valid JSON with this exact structure:
{
  "patterns": [
    {
      "type": "one of the taxonomy labels above",
      "description": "Specific description of the deceptive pattern",
      "severity": "low|medium|high|critical",
      "location": "Where on page (header, product card, checkout, modal, etc.)",
      "evidence": "Exact text/element that proves the pattern",
      "confidence": 0.85,
      "bbox": [x, y, width, height] // Optional
    }
  ],
  "summary": {
    "total_patterns": 5,
    "prevalence_score": 0.75,
    "primary_categories": ["choose from taxonomy above"]
  }
}

‚ö†Ô∏è VALIDATION RULES:
1. If providing "bbox", it MUST have exactly 4 non-negative integers: [x, y, width, height]
2. Only include patterns with confidence > 0.7
3. Text-only patterns are WELCOME. Do not filter them out.

Return ONLY valid JSON. No explanations, no markdown, just the JSON object.`;

export default function DatasetCollection() {
  const [entries, setEntries] = useState<DatasetEntry[]>([]);
  const [analyzing, setAnalyzing] = useState(false);
  const [exportingBundle, setExportingBundle] = useState(false);
  const [progress, setProgress] = useState<{
    current: number;
    total: number;
    url: string;
    status: string;
  } | null>(null);
  const [urlQueue, setUrlQueue] = useState<string[]>([]);
  const [isProcessingQueue, setIsProcessingQueue] = useState(false);
  const [filterPattern, setFilterPattern] = useState<string>('ALL');
  const [isRecursiveCrawling, setIsRecursiveCrawling] = useState(false);
  const [crawlProgress, setCrawlProgress] = useState<{
    discovered: number;
    visited: number;
    queue: number;
    currentUrl: string;
  } | null>(null);
  const [statistics, setStatistics] = useState<{
    totalEntries: number;
    totalPatterns: number;
    prevalenceRate: number;
    pakistaniSitesScanned: number;
    categoryBreakdown: Record<string, number>;
  }>({
    totalEntries: 0,
    totalPatterns: 0,
    prevalenceRate: 0,
    pakistaniSitesScanned: 0,
    categoryBreakdown: {},
  });
  const [editingEntry, setEditingEntry] = useState<DatasetEntry | null>(null);
  const [showBboxEditor, setShowBboxEditor] = useState(false);

  // Use global AI configuration hook
  const { readyState } = useGlobalAIConfig();

  // Load entries on mount
  useEffect(() => {
    loadEntries();
  }, []);

  // Calculate statistics when entries change
  useEffect(() => {
    calculateStatistics();
  }, [entries]);

  const calculateStatistics = () => {
    const totalEntries = entries.length;
    const totalPatterns = entries.reduce(
      (sum, e) => sum + e.patterns.length,
      0,
    );
    const sitesWithPatterns = entries.filter(
      (e) => e.patterns.length > 0,
    ).length;
    const prevalenceRate =
      totalEntries > 0 ? (sitesWithPatterns / totalEntries) * 100 : 0;

    const categoryBreakdown: Record<string, number> = {};
    entries.forEach((entry) => {
      entry.patterns.forEach((pattern) => {
        categoryBreakdown[pattern.type] =
          (categoryBreakdown[pattern.type] || 0) + 1;
      });
    });

    const pakistaniSitesScanned = entries.filter(
      (e) => e.metadata?.researchContext?.isPakistaniEcommerce,
    ).length;

    setStatistics({
      totalEntries,
      totalPatterns,
      prevalenceRate: Math.round(prevalenceRate * 100) / 100,
      categoryBreakdown,
      pakistaniSitesScanned,
    });
  };

  const loadEntries = async () => {
    try {
      const data = await getDatasetEntries();
      // Sort by timestamp descending
      data.sort((a, b) => b.timestamp - a.timestamp);
      setEntries(data);
    } catch (error) {
      console.error('Failed to load entries:', error);
      message.error('Failed to load dataset entries');
    }
  };

  const filteredEntries =
    filterPattern === 'ALL'
      ? entries
      : entries.filter((entry) =>
          entry.patterns.some((p) => p.type === filterPattern),
        );

  const getCurrentTab = async () => {
    const tabs = await chrome.tabs.query({ active: true, currentWindow: true });
    return tabs[0];
  };

  const waitForPageLoad = async (
    tabId: number,
    maxWait = 10000,
  ): Promise<void> => {
    return new Promise((resolve, reject) => {
      const startTime = Date.now();

      const checkReady = async () => {
        try {
          const results = await chrome.scripting.executeScript({
            target: { tabId },
            func: () => document.readyState,
          });

          if (results[0]?.result === 'complete') {
            // Wait a bit more for dynamic content
            await new Promise((r) => setTimeout(r, 2000));
            resolve();
            return;
          }

          if (Date.now() - startTime > maxWait) {
            reject(new Error('Page load timeout'));
            return;
          }

          setTimeout(checkReady, 500);
        } catch (error) {
          reject(error);
        }
      };

      checkReady();
    });
  };

  const capturePageData = async (tabId: number) => {
    // Get tab first to get windowId
    const tab = await chrome.tabs.get(tabId);

    if (
      !tab.url ||
      tab.url.startsWith('chrome://') ||
      tab.url.startsWith('chrome-extension://')
    ) {
      throw new Error('Cannot capture Chrome internal pages');
    }

    // Wait for page to be ready
    await waitForPageLoad(tabId);

    // Capture screenshot
    const screenshot = await new Promise<string>((resolve, reject) => {
      chrome.tabs.captureVisibleTab(
        tab.windowId!,
        { format: 'png', quality: 90 },
        (dataUrl) => {
          if (chrome.runtime.lastError) {
            reject(new Error(chrome.runtime.lastError.message));
          } else if (!dataUrl) {
            reject(new Error('Failed to capture screenshot'));
          } else {
            resolve(dataUrl);
          }
        },
      );
    });

    // Capture DOM
    const domResults = await chrome.scripting.executeScript({
      target: { tabId },
      func: () => document.documentElement.outerHTML,
    });

    const dom = domResults[0]?.result || '';
    if (!dom) {
      throw new Error('Failed to capture DOM');
    }

    // Get viewport size
    const viewportResults = await chrome.scripting.executeScript({
      target: { tabId },
      func: () => ({
        width: window.innerWidth || document.documentElement.clientWidth,
        height: window.innerHeight || document.documentElement.clientHeight,
      }),
    });

    const viewport = viewportResults[0]?.result || {
      width: 1920,
      height: 1080,
    };

    // Get page metadata
    const metadata = {
      pageTitle: tab.title || undefined,
      viewport,
      userAgent: navigator.userAgent,
    };

    return {
      screenshot,
      dom,
      metadata,
      url: tab.url,
    };
  };

  const analyzePageForDarkPatterns = async (
    screenshot: string,
    dom: string,
    url: string,
    retries = 3,
  ): Promise<{ patterns: DarkPattern[]; summary?: any }> => {
    // Get active model config from centralized storage
    const modelConfig = await getActiveModelConfig();
    // This function will crop individual images for each pattern
    const messageContent: AIArgs[0]['content'] = [
      {
        type: 'image_url',
        image_url: {
          url: screenshot,
          detail: 'high',
        },
      },
      {
        type: 'text',
        text: `${DARK_PATTERN_PROMPT}\n\nURL: ${url}\n\nDOM (first 5000 chars):\n${dom.substring(0, 5000)}`,
      },
    ];

    const prompt: AIArgs = [
      {
        role: 'system',
        content:
          'You are a dark pattern detection expert specializing in Pakistani e-commerce. Analyze webpages for deceptive UI patterns in both English, Urdu (Perso-Arabic script), and Roman Urdu (Latin script). Return ONLY valid JSON.',
      },
      {
        role: 'user',
        content: messageContent,
      },
    ];

    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const response = await callAIWithObjectResponse<{
          patterns: DarkPattern[];
          summary?: {
            total_patterns: number;
            prevalence_score: number;
            primary_categories: string[];
          };
        }>(prompt, AIActionType.EXTRACT_DATA, modelConfig);

        // Validate response
        if (!response || !response.content) {
          throw new Error('Invalid response from AI model');
        }

        const patterns = response.content.patterns || [];
        const summary = response.content.summary;

        // Validate and filter patterns
        const validPatterns = patterns.filter((p) => {
          // Filter by confidence threshold
          if (p.confidence !== undefined && p.confidence <= 0.7) {
            return false;
          }

          // Relaxed Bounding Box Validation:
          // We allow patterns WITHOUT bbox (text-only patterns)
          // But IF bbox is present, it must be valid.

          if (p.bbox) {
            if (!Array.isArray(p.bbox) || p.bbox.length !== 4) {
              // Invalid bbox format -> Keep pattern but strip bbox? Or reject?
              // Let's strip the invalid bbox and keep the pattern as text-only
              console.warn(
                `Pattern "${p.type}" has invalid bbox format, removing bbox`,
                p.bbox,
              );
              p.bbox = undefined;
              return true;
            }

            const [x, y, width, height] = p.bbox;
            if (
              typeof x !== 'number' ||
              typeof y !== 'number' ||
              typeof width !== 'number' ||
              typeof height !== 'number' ||
              x < 0 ||
              y < 0 ||
              width <= 0 ||
              height <= 0 ||
              !Number.isFinite(x) ||
              !Number.isFinite(y) ||
              !Number.isFinite(width) ||
              !Number.isFinite(height)
            ) {
              console.warn(
                `Pattern "${p.type}" has invalid bbox values, removing bbox`,
                p.bbox,
              );
              p.bbox = undefined;
              return true;
            }

            // Normalize bbox to integers
            p.bbox = [
              Math.round(x),
              Math.round(y),
              Math.round(width),
              Math.round(height),
            ];
          }

          return true;
        });

        // Warn if patterns were filtered out
        if (patterns.length > validPatterns.length) {
          const filteredCount = patterns.length - validPatterns.length;
          console.warn(
            `Filtered out ${filteredCount} pattern(s) due to low confidence`,
          );
        }

        // CRITICAL: Crop individual images for each pattern
        // Each pattern gets its own cropped image showing ONLY that specific dark pattern
        const patternsWithCroppedImages = await Promise.all(
          validPatterns.map(async (pattern) => {
            if (pattern.bbox && pattern.bbox.length === 4) {
              try {
                const croppedImage = await cropImageFromBbox(
                  screenshot,
                  pattern.bbox,
                );
                return {
                  ...pattern,
                  croppedImage, // Individual cropped image for THIS pattern only
                };
              } catch (error) {
                console.error(
                  `Failed to crop image for pattern "${pattern.type}":`,
                  error,
                );
                return pattern; // Return pattern without cropped image if cropping fails
              }
            }
            return pattern;
          }),
        );

        return {
          patterns: patternsWithCroppedImages,
          summary,
        };
      } catch (error: any) {
        lastError = error;
        console.error(`Analysis attempt ${attempt} failed:`, error);

        if (attempt < retries) {
          // Wait before retry (exponential backoff)
          await new Promise((resolve) => setTimeout(resolve, 1000 * attempt));
        }
      }
    }

    // All retries failed
    throw new Error(
      `Failed to analyze page after ${retries} attempts: ${lastError?.message || 'Unknown error'}`,
    );
  };

  const analyzeCurrentPage = async () => {
    // Validate model configuration using centralized config
    if (!readyState.isReady) {
      Modal.warning({
        title: 'Model Configuration Required',
        content: `${readyState.errorMessage} Please configure your AI model settings first.`,
      });
      return;
    }

    setAnalyzing(true);
    try {
      const tab = await getCurrentTab();
      if (!tab.id || !tab.url) {
        message.error('No active tab found');
        setAnalyzing(false);
        return;
      }

      if (
        tab.url.startsWith('chrome://') ||
        tab.url.startsWith('chrome-extension://')
      ) {
        message.error('Cannot analyze Chrome internal pages');
        setAnalyzing(false);
        return;
      }

      // Check if Pakistani e-commerce site
      const isPakistaniSite = isPakistaniEcommerceSite(tab.url);
      const siteName = getSiteName(tab.url);

      if (!isPakistaniSite) {
        Modal.confirm({
          title: 'Not a Pakistani E-commerce Site',
          content:
            'This page does not appear to be a Pakistani e-commerce site. Continue analysis anyway?',
          onOk: async () => {
            try {
              await performAnalysis(tab, isPakistaniSite, siteName);
            } catch (error: any) {
              console.error('Error in performAnalysis:', error);
              message.error(
                `Failed to analyze page: ${error.message || 'Unknown error'}`,
              );
            } finally {
              setAnalyzing(false);
            }
          },
          onCancel: () => {
            setAnalyzing(false);
          },
        });
        return;
      }

      try {
        await performAnalysis(tab, isPakistaniSite, siteName);
      } finally {
        setAnalyzing(false);
      }
    } catch (error: any) {
      console.error('Error analyzing page:', error);
      message.error(
        `Failed to analyze page: ${error.message || 'Unknown error'}`,
      );
      setAnalyzing(false);
    }
  };

  const performAnalysis = async (
    tab: chrome.tabs.Tab,
    isPakistaniSite: boolean,
    siteName: string | null,
  ) => {
    try {
      message.loading({
        content: 'Capturing page data...',
        key: 'analysis',
        duration: 0,
      });

      const { screenshot, dom, metadata, url } = await capturePageData(tab.id!);

      message.loading({
        content: 'Analyzing for dark patterns with AI...',
        key: 'analysis',
        duration: 0,
      });

      const modelConfig = await getActiveModelConfig();
      if (!modelConfig || !modelConfig.modelName) {
        throw new Error('AI model not configured');
      }

      const { patterns, summary } = await analyzePageForDarkPatterns(
        screenshot,
        dom,
        url,
      );

      // Create dataset entry with research metadata
      const entry: DatasetEntry = {
        id: `entry-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
        url,
        timestamp: Date.now(),
        screenshot,
        dom: dom.substring(0, 10000), // Store first 10k chars to save space
        patterns,
        summary, // Include summary from AI analysis
        metadata: {
          ...metadata,
          researchContext: {
            isPakistaniEcommerce: isPakistaniSite,
            siteName: siteName || undefined,
            modelUsed: modelConfig.modelName,
            analysisVersion: '2.1', // Updated to include Roman Urdu support
          },
        },
      };

      await storeDatasetEntry(entry);

      message.destroy('analysis');

      // Show success message with bbox validation info
      const patternsWithBbox = patterns.filter(
        (p) => p.bbox && p.bbox.length === 4,
      ).length;
      if (patterns.length > 0 && patternsWithBbox === patterns.length) {
        message.success({
          content: `Analysis complete! Found ${patterns.length} dark pattern(s) with bounding boxes`,
          duration: 5,
        });
      } else if (patterns.length > 0) {
        message.warning({
          content: `Analysis complete! Found ${patterns.length} pattern(s), but ${patterns.length - patternsWithBbox} were filtered due to missing bounding boxes.`,
          duration: 7,
        });
      } else {
        message.success({
          content: 'Analysis complete! No dark patterns detected.',
          duration: 5,
        });
      }

      await loadEntries();
    } catch (error: any) {
      message.destroy('analysis');
      throw error;
    }
  };

  const processUrlQueue = async () => {
    if (urlQueue.length === 0 || isProcessingQueue) return;

    if (!readyState.isReady) {
      Modal.warning({
        title: 'Model Configuration Required',
        content: `${readyState.errorMessage} Please configure your AI model settings first.`,
      });
      return;
    }

    setIsProcessingQueue(true);
    const modelConfig = await getActiveModelConfig();
    if (!modelConfig || !modelConfig.modelName) {
      message.error('AI model not configured');
      setIsProcessingQueue(false);
      return;
    }

    let successCount = 0;
    let failCount = 0;

    for (let i = 0; i < urlQueue.length; i++) {
      const url = urlQueue[i];
      setProgress({
        current: i + 1,
        total: urlQueue.length,
        url,
        status: 'Processing...',
      });

      let tab: chrome.tabs.Tab | null = null;

      try {
        // Validate URL
        const validation = validateUrl(url);
        if (!validation.valid) {
          throw new Error(validation.error || 'Invalid URL');
        }

        setProgress((prev) =>
          prev ? { ...prev, status: 'Opening page...' } : null,
        );

        // Open URL in new tab
        tab = await chrome.tabs.create({ url, active: false });

        if (!tab.id) {
          throw new Error('Failed to create tab');
        }

        setProgress((prev) =>
          prev ? { ...prev, status: 'Waiting for page to load...' } : null,
        );

        // Wait for page to load properly
        await waitForPageLoad(tab.id, 15000);

        setProgress((prev) =>
          prev ? { ...prev, status: 'Capturing page data...' } : null,
        );

        // Capture and analyze
        const { screenshot, dom, metadata } = await capturePageData(tab.id);

        const isPakistaniSite = isPakistaniEcommerceSite(url);
        const siteName = getSiteName(url);

        setProgress((prev) =>
          prev ? { ...prev, status: 'Analyzing with AI...' } : null,
        );

        const { patterns, summary } = await analyzePageForDarkPatterns(
          screenshot,
          dom,
          url,
        );

        const entry: DatasetEntry = {
          id: `entry-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
          url,
          timestamp: Date.now(),
          screenshot,
          dom: dom.substring(0, 10000),
          patterns,
          metadata: {
            ...metadata,
            researchContext: {
              isPakistaniEcommerce: isPakistaniSite,
              siteName: siteName || undefined,
              modelUsed: modelConfig.modelName,
              analysisVersion: '2.1', // Updated to include Roman Urdu support
            },
          },
        };

        await storeDatasetEntry(entry);
        successCount++;

        // Close tab
        if (tab.id) {
          await chrome.tabs.remove(tab.id);
        }
      } catch (error: any) {
        console.error(`Error processing ${url}:`, error);
        failCount++;

        // Close tab if it was created
        if (tab?.id) {
          try {
            await chrome.tabs.remove(tab.id);
          } catch (e) {
            // Ignore errors when closing tab
          }
        }

        message.warning(
          `Failed to process ${url}: ${error.message || 'Unknown error'}`,
        );
      }
    }

    setProgress(null);
    setUrlQueue([]);
    setIsProcessingQueue(false);

    message.success({
      content: `Batch processing complete! ${successCount} succeeded, ${failCount} failed.`,
      duration: 5,
    });

    await loadEntries();
  };

  const handleBatchProcess = () => {
    Modal.confirm({
      title: 'Batch Process URLs',
      content: (
        <div>
          <p>Enter URLs to process (one per line):</p>
          <textarea
            id="url-input"
            style={{
              width: '100%',
              minHeight: '200px',
              fontFamily: 'monospace',
            }}
            placeholder="https://example.com&#10;https://example2.com"
          />
        </div>
      ),
      onOk: () => {
        const input = document.getElementById(
          'url-input',
        ) as HTMLTextAreaElement;
        const urls = input.value
          .split('\n')
          .map((u) => u.trim())
          .filter((u) => u?.startsWith('http'));

        if (urls.length === 0) {
          message.error('No valid URLs provided');
          return;
        }

        setUrlQueue(urls);
        processUrlQueue();
      },
    });
  };

  const handleAutoDiscoverLinks = async () => {
    try {
      const tab = await getCurrentTab();
      if (!tab?.id || !tab.url) {
        message.error('No active tab found');
        return;
      }

      // Show options modal first
      Modal.confirm({
        title: 'Enhanced Auto Crawl Options',
        width: 700,
        content: (
          <div style={{ marginTop: 16 }}>
            <p>Choose crawling strategy:</p>
            <ul style={{ marginTop: 8, paddingLeft: 20, lineHeight: '1.8' }}>
              <li>
                <strong>Quick Scan:</strong> Current page only (fast, ~50-200
                links)
              </li>
              <li>
                <strong>Deep Scan:</strong> Scroll page + wait for dynamic
                content (~200-1000 links)
              </li>
              <li>
                <strong>üï∑Ô∏è Full Website Crawl:</strong> Recursively follows ALL
                links to discover EVERY page on the website (comprehensive, may
                take 10-30 minutes)
              </li>
            </ul>
            <p style={{ marginTop: 12, color: '#666', fontSize: '12px' }}>
              <strong>Full Website Crawl:</strong> Will visit every page, follow
              all internal links, and discover the entire website structure.
              Perfect for complete coverage.
            </p>
          </div>
        ),
        okText: 'üï∑Ô∏è Full Website Crawl',
        cancelText: 'Deep Scan',
        onOk: async () => {
          await performRecursiveWebsiteCrawl(tab.id!, tab.url!);
        },
        onCancel: async () => {
          await performDeepLinkDiscovery(tab.id!);
        },
      });
    } catch (error: any) {
      console.error('Auto-discover links error:', error);
      message.error(
        `Failed to auto-discover links: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`,
      );
    }
  };

  const performQuickLinkDiscovery = async (tabId: number) => {
    try {
      const results = await chrome.scripting.executeScript({
        target: { tabId },
        func: () => {
          const anchors = Array.from(
            document.querySelectorAll<HTMLAnchorElement>('a[href]'),
          );
          const origin = location.origin;
          const urls = new Set<string>();

          for (const a of anchors) {
            const rawHref = a.getAttribute('href') || a.href;
            if (!rawHref) continue;
            try {
              const absolute = new URL(rawHref, location.href).href;
              if (absolute.startsWith(origin)) {
                urls.add(absolute);
              }
            } catch {
              // ignore malformed hrefs
            }
          }

          return Array.from(urls);
        },
      });

      const discovered: string[] = results[0]?.result || [];
      showLinkDiscoveryResult(discovered);
    } catch (error: any) {
      message.error(`Failed to discover links: ${error.message}`);
    }
  };

  const performDeepLinkDiscovery = async (tabId: number) => {
    try {
      message.loading({
        content: 'Scanning page (this may take 30-60 seconds)...',
        key: 'crawl',
        duration: 0,
      });

      const results = await chrome.scripting.executeScript({
        target: { tabId },
        func: async () => {
          const origin = location.origin;
          const urls = new Set<string>();
          let lastHeight = 0;
          let scrollAttempts = 0;
          const maxScrollAttempts = 10; // Prevent infinite scroll

          // Function to collect all links
          const collectLinks = () => {
            const anchors = Array.from(
              document.querySelectorAll<HTMLAnchorElement>('a[href]'),
            );

            for (const a of anchors) {
              const rawHref = a.getAttribute('href') || a.href;
              if (!rawHref) continue;
              try {
                const absolute = new URL(rawHref, location.href).href;
                if (absolute.startsWith(origin)) {
                  // Filter out common non-content URLs
                  const urlLower = absolute.toLowerCase();
                  if (
                    !urlLower.includes('/api/') &&
                    !urlLower.includes('/ajax/') &&
                    !urlLower.includes('/json/') &&
                    !urlLower.includes('#') &&
                    !urlLower.includes('javascript:') &&
                    !urlLower.includes('mailto:') &&
                    !urlLower.includes('tel:')
                  ) {
                    urls.add(absolute);
                  }
                }
              } catch {
                // ignore malformed hrefs
              }
            }
          };

          // Initial collection
          collectLinks();

          // Scroll and collect (for lazy-loaded content)
          while (scrollAttempts < maxScrollAttempts) {
            // Scroll to bottom
            window.scrollTo(0, document.body.scrollHeight);

            // Wait for content to load
            await new Promise((resolve) => setTimeout(resolve, 2000));

            // Check if page height changed (new content loaded)
            const currentHeight = document.body.scrollHeight;
            if (currentHeight === lastHeight) {
              // No new content, try a few more times
              scrollAttempts++;
              if (scrollAttempts >= 3) break;
            } else {
              scrollAttempts = 0; // Reset if new content found
            }

            lastHeight = currentHeight;

            // Collect links after scroll
            collectLinks();

            // Try clicking "Load More" or "See More" buttons if they exist
            const loadMoreButtons = Array.from(
              document.querySelectorAll<HTMLElement>(
                'button, a, div[role="button"]',
              ),
            ).filter((el) => {
              const text = el.textContent?.toLowerCase() || '';
              return (
                text.includes('load more') ||
                text.includes('see more') ||
                text.includes('show more') ||
                text.includes('ÿ≤€åÿßÿØ€Å ÿØ€å⁄©⁄æ€å⁄∫') ||
                text.includes('aur dekhein')
              );
            });

            if (loadMoreButtons.length > 0) {
              try {
                loadMoreButtons[0].click();
                await new Promise((resolve) => setTimeout(resolve, 3000));
                collectLinks();
              } catch {
                // Ignore click errors
              }
            }
          }

          // Scroll back to top
          window.scrollTo(0, 0);
          await new Promise((resolve) => setTimeout(resolve, 1000));
          collectLinks();

          return Array.from(urls);
        },
      });

      message.destroy('crawl');
      const discovered: string[] = results[0]?.result || [];
      showLinkDiscoveryResult(discovered);
    } catch (error: any) {
      message.destroy('crawl');
      message.error(`Failed to discover links: ${error.message}`);
    }
  };

  // Normalize URL to avoid duplicates (remove fragments, trailing slashes, etc.)
  const normalizeUrl = (url: string): string => {
    try {
      const urlObj = new URL(url);
      // Remove fragment
      urlObj.hash = '';
      // Remove trailing slash (except for root)
      if (urlObj.pathname !== '/' && urlObj.pathname.endsWith('/')) {
        urlObj.pathname = urlObj.pathname.slice(0, -1);
      }
      // Sort query params for consistency
      const params = new URLSearchParams(urlObj.search);
      urlObj.search = params.toString();
      return urlObj.href;
    } catch {
      return url;
    }
  };

  // Check if URL should be crawled (filters out API endpoints, etc.)
  const shouldCrawlUrl = (url: string, baseOrigin: string): boolean => {
    try {
      const urlObj = new URL(url);
      // Must be same origin
      if (urlObj.origin !== baseOrigin) return false;

      const urlLower = url.toLowerCase();
      // Exclude API endpoints
      if (
        urlLower.includes('/api/') ||
        urlLower.includes('/ajax/') ||
        urlLower.includes('/json/') ||
        urlLower.includes('/graphql') ||
        urlLower.includes('/rest/') ||
        urlLower.includes('javascript:') ||
        urlLower.includes('mailto:') ||
        urlLower.includes('tel:') ||
        urlLower.includes('#') ||
        urlLower.includes('.pdf') ||
        urlLower.includes('.jpg') ||
        urlLower.includes('.png') ||
        urlLower.includes('.gif') ||
        urlLower.includes('.zip') ||
        urlLower.includes('.exe')
      ) {
        return false;
      }

      // Exclude common non-content paths
      const path = urlObj.pathname.toLowerCase();
      if (
        path.includes('/admin/') ||
        path.includes('/private/') ||
        path.includes('/internal/') ||
        path.includes('/_next/') ||
        path.includes('/static/') ||
        path.includes('/assets/')
      ) {
        return false;
      }

      return true;
    } catch {
      return false;
    }
  };

  const performRecursiveWebsiteCrawl = async (
    startTabId: number,
    startUrl: string,
  ) => {
    if (isRecursiveCrawling) {
      message.warning('Recursive crawl already in progress');
      return;
    }

    try {
      const startUrlObj = new URL(startUrl);
      const baseOrigin = startUrlObj.origin;

      Modal.confirm({
        title: 'üï∑Ô∏è Full Website Crawl',
        width: 600,
        content: (
          <div style={{ marginTop: 16 }}>
            <p>
              This will recursively crawl the <strong>ENTIRE website</strong>{' '}
              starting from:
            </p>
            <p
              style={{
                wordBreak: 'break-all',
                background: '#f5f5f5',
                padding: '8px',
                borderRadius: '4px',
                fontSize: '12px',
              }}
            >
              {startUrl}
            </p>
            <div style={{ marginTop: 16 }}>
              <p>
                <strong>How it works:</strong>
              </p>
              <ul style={{ paddingLeft: 20, fontSize: '12px' }}>
                <li>Starts from current page</li>
                <li>Discovers all links on each page</li>
                <li>Visits each new page found</li>
                <li>Continues until ALL pages are discovered</li>
                <li>Skips already visited pages (no duplicates)</li>
              </ul>
            </div>
            <p style={{ marginTop: 16, color: '#ff4d4f', fontSize: '12px' }}>
              <strong>‚ö†Ô∏è Warning:</strong> This may take 10-30 minutes for large
              websites and will discover thousands of pages. Make sure you have
              enough API credits.
            </p>
          </div>
        ),
        okText: 'Start Full Crawl',
        cancelText: 'Cancel',
        onOk: async () => {
          setIsRecursiveCrawling(true);
          setCrawlProgress({
            discovered: 0,
            visited: 0,
            queue: 1,
            currentUrl: startUrl,
          });

          const visitedUrls = new Set<string>();
          const urlQueue: string[] = [normalizeUrl(startUrl)];
          const allDiscoveredUrls = new Set<string>();

          let currentIndex = 0;
          const maxPages = 10000; // Safety limit
          const delayBetweenPages = 2000; // 2 seconds between page visits

          message.loading({
            content: 'Starting full website crawl... This will take a while.',
            key: 'recursive-crawl',
            duration: 0,
          });

          while (currentIndex < urlQueue.length && currentIndex < maxPages) {
            const currentUrl = urlQueue[currentIndex];
            const normalizedUrl = normalizeUrl(currentUrl);

            // Skip if already visited
            if (visitedUrls.has(normalizedUrl)) {
              currentIndex++;
              continue;
            }

            setCrawlProgress({
              discovered: allDiscoveredUrls.size,
              visited: visitedUrls.size,
              queue: urlQueue.length - currentIndex,
              currentUrl: currentUrl,
            });

            message.loading({
              content: `Crawling: ${visitedUrls.size} visited, ${allDiscoveredUrls.size} discovered, ${urlQueue.length - currentIndex} in queue\nCurrent: ${currentUrl.substring(0, 60)}...`,
              key: 'recursive-crawl',
              duration: 0,
            });

            try {
              // Open URL in new tab
              const tab = await chrome.tabs.create({
                url: currentUrl,
                active: false,
              });

              if (!tab.id) {
                currentIndex++;
                continue;
              }

              // Wait for page to load
              await waitForPageLoad(tab.id, 15000);

              // Discover links on this page
              const discoveredLinks = await chrome.scripting.executeScript({
                target: { tabId: tab.id },
                func: async () => {
                  const origin = location.origin;
                  const urls = new Set<string>();
                  let lastHeight = 0;
                  let scrollAttempts = 0;
                  const maxScrollAttempts = 8; // Increased attempts

                  // Recursive function to find links, piercing Shadow DOMs
                  const findLinksInNode = (
                    root: Document | ShadowRoot | Element,
                  ) => {
                    // Get links in current root
                    const anchors = Array.from(
                      root.querySelectorAll('a[href]'),
                    ) as HTMLAnchorElement[];

                    anchors.forEach((a) => {
                      try {
                        const rawHref = a.getAttribute('href') || a.href;
                        if (!rawHref) return;

                        const absolute = new URL(rawHref, location.href).href;

                        // Relaxed filtering: Allow same-domain and subdomains if logical
                        // We mainly check if it's http/https and not some other protocol
                        const urlObj = new URL(absolute);

                        if (
                          urlObj.protocol !== 'http:' &&
                          urlObj.protocol !== 'https:'
                        )
                          return;

                        // Basic exclusion of non-page resources
                        const urlLower = absolute.toLowerCase();
                        if (
                          urlLower.includes('javascript:') ||
                          urlLower.includes('mailto:') ||
                          urlLower.includes('tel:') ||
                          urlLower.match(
                            /\.(png|jpg|jpeg|gif|svg|pdf|zip|css|js|woff|woff2)$/i,
                          )
                        ) {
                          return;
                        }

                        // Check if it belongs to the same domain (allowing subdomains for now, or strict origin?)
                        // User wants "all links that I use for the scratching", implying same site.
                        // Let's stick to origin startsWith for safety against external links,
                        // but we can be slightly looser if needed. For now, origin check is standard for "crawling a site".
                        if (absolute.startsWith(origin)) {
                          urlObj.hash = ''; // Remove fragments
                          if (
                            urlObj.pathname !== '/' &&
                            urlObj.pathname.endsWith('/')
                          ) {
                            urlObj.pathname = urlObj.pathname.slice(0, -1);
                          }
                          urls.add(urlObj.href);
                        }
                      } catch (e) {
                        /* ignore invalid URLs */
                      }
                    });

                    // Traverse children to find Shadow Roots
                    const allNodes = root.querySelectorAll('*');
                    allNodes.forEach((node) => {
                      if (node.shadowRoot) {
                        findLinksInNode(node.shadowRoot);
                      }
                    });
                  };

                  const collectLinks = () => {
                    findLinksInNode(document);
                  };

                  collectLinks();

                  // Robust scroll to load lazy content
                  for (let i = 0; i < maxScrollAttempts; i++) {
                    window.scrollTo(0, document.body.scrollHeight);
                    // Wait longer for hydration/network
                    await new Promise((resolve) => setTimeout(resolve, 2500));

                    const currentHeight = document.body.scrollHeight;
                    if (currentHeight === lastHeight) {
                      scrollAttempts++;
                      // If stuck for 2 attempts, try scrolling up a bit and back down to trigger scroll events
                      if (scrollAttempts >= 2) {
                        window.scrollTo(0, document.body.scrollHeight - 500);
                        await new Promise((resolve) =>
                          setTimeout(resolve, 500),
                        );
                        window.scrollTo(0, document.body.scrollHeight);
                        await new Promise((resolve) =>
                          setTimeout(resolve, 1000),
                        );
                        if (document.body.scrollHeight === lastHeight) break; // Still stuck
                      }
                    } else {
                      scrollAttempts = 0;
                    }
                    lastHeight = currentHeight;
                    collectLinks();
                  }

                  return Array.from(urls);
                },
              });

              const links = discoveredLinks[0]?.result || [];

              // Add new links to queue
              for (const link of links) {
                const normalized = normalizeUrl(link);
                if (
                  shouldCrawlUrl(link, baseOrigin) &&
                  !visitedUrls.has(normalized) &&
                  !urlQueue.includes(normalized)
                ) {
                  urlQueue.push(normalized);
                  allDiscoveredUrls.add(normalized);
                }
              }

              // Mark as visited
              visitedUrls.add(normalizedUrl);

              // Close tab
              await chrome.tabs.remove(tab.id);

              // Delay between pages to avoid overwhelming the server
              await new Promise((resolve) =>
                setTimeout(resolve, delayBetweenPages),
              );
            } catch (error: any) {
              console.error(`Error crawling ${currentUrl}:`, error);
              // Mark as visited even if failed to avoid retrying
              visitedUrls.add(normalizedUrl);
            }

            currentIndex++;
          }

          message.destroy('recursive-crawl');
          setIsRecursiveCrawling(false);
          setCrawlProgress(null);

          const finalUrls = Array.from(allDiscoveredUrls);

          Modal.success({
            title: '‚úÖ Full Website Crawl Complete!',
            width: 700,
            content: (
              <div style={{ marginTop: 16 }}>
                <p>
                  <strong>Website crawl finished!</strong>
                </p>
                <div style={{ marginTop: 12 }}>
                  <p>
                    <strong>Total pages discovered:</strong> {finalUrls.length}
                  </p>
                  <p>
                    <strong>Pages visited:</strong> {visitedUrls.size}
                  </p>
                </div>
                <div
                  style={{
                    marginTop: 16,
                    maxHeight: '200px',
                    overflow: 'auto',
                    border: '1px solid #d9d9d9',
                    padding: '8px',
                    borderRadius: '4px',
                  }}
                >
                  <p
                    style={{
                      fontSize: '12px',
                      marginBottom: '8px',
                      fontWeight: 'bold',
                    }}
                  >
                    Sample URLs:
                  </p>
                  {finalUrls.slice(0, 20).map((url, idx) => (
                    <p
                      key={idx}
                      style={{
                        fontSize: '11px',
                        margin: '4px 0',
                        wordBreak: 'break-all',
                      }}
                    >
                      {url}
                    </p>
                  ))}
                  {finalUrls.length > 20 && (
                    <p
                      style={{
                        fontSize: '11px',
                        color: '#666',
                        marginTop: '8px',
                      }}
                    >
                      ... and {finalUrls.length - 20} more
                    </p>
                  )}
                </div>
                <p style={{ marginTop: 16, color: '#666', fontSize: '12px' }}>
                  <small>
                    Ready to process all {finalUrls.length} pages for dark
                    pattern analysis.
                  </small>
                </p>
              </div>
            ),
            okText: `Process All (${finalUrls.length})`,
            onOk: () => {
              setUrlQueue(finalUrls);
              processUrlQueue();
            },
          });
        },
      });
    } catch (error: any) {
      message.error(`Failed to start recursive crawl: ${error.message}`);
      setIsRecursiveCrawling(false);
      setCrawlProgress(null);
    }
  };

  const showLinkDiscoveryResult = (discovered: string[]) => {
    if (!discovered.length) {
      message.warning('No internal links discovered on this page');
      return;
    }

    // Filter and categorize URLs
    const categorized = {
      product: discovered.filter(
        (url) =>
          url.match(/\/product\//i) ||
          url.match(/\/p\//i) ||
          url.match(/\/item\//i) ||
          url.match(/\/dp\//i),
      ),
      category: discovered.filter(
        (url) =>
          url.match(/\/category\//i) ||
          url.match(/\/c\//i) ||
          url.match(/\/shop\//i),
      ),
      other: discovered.filter(
        (url) =>
          !url.match(/\/product\//i) &&
          !url.match(/\/p\//i) &&
          !url.match(/\/item\//i) &&
          !url.match(/\/dp\//i) &&
          !url.match(/\/category\//i) &&
          !url.match(/\/c\//i) &&
          !url.match(/\/shop\//i),
      ),
    };

    Modal.confirm({
      title: 'Auto Crawl Results',
      width: 700,
      content: (
        <div style={{ marginTop: 16 }}>
          <p>
            <strong>Total links discovered: {discovered.length}</strong>
          </p>
          <div style={{ marginTop: 12 }}>
            <p>
              <strong>Product pages:</strong> {categorized.product.length}
            </p>
            <p>
              <strong>Category pages:</strong> {categorized.category.length}
            </p>
            <p>
              <strong>Other pages:</strong> {categorized.other.length}
            </p>
          </div>
          <div
            style={{
              marginTop: 16,
              maxHeight: '200px',
              overflow: 'auto',
              border: '1px solid #d9d9d9',
              padding: '8px',
              borderRadius: '4px',
            }}
          >
            <p
              style={{
                fontSize: '12px',
                marginBottom: '8px',
                fontWeight: 'bold',
              }}
            >
              Sample URLs:
            </p>
            {discovered.slice(0, 10).map((url, idx) => (
              <p
                key={idx}
                style={{
                  fontSize: '11px',
                  margin: '4px 0',
                  wordBreak: 'break-all',
                }}
              >
                {url}
              </p>
            ))}
            {discovered.length > 10 && (
              <p style={{ fontSize: '11px', color: '#666', marginTop: '8px' }}>
                ... and {discovered.length - 10} more
              </p>
            )}
          </div>
          <p style={{ marginTop: 16, color: '#666', fontSize: '12px' }}>
            <small>
              Note: Processing all {discovered.length} pages may take a while.
              Consider filtering by type first.
            </small>
          </p>
        </div>
      ),
      okText: `Process All (${discovered.length})`,
      cancelText: 'Cancel',
      onOk: () => {
        setUrlQueue(discovered);
        processUrlQueue();
      },
    });
  };

  // Fallback download in popup (in case service worker download fails on some browsers)
  const triggerFallbackDownload = (data: string, filename: string) => {
    try {
      const blob = new Blob([data], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
      message.success('Dataset exported (fallback download)');
    } catch (error) {
      console.error('Fallback export error:', error);
      message.error('Failed to export dataset (fallback)');
    }
  };

  const handleExport = async () => {
    try {
      const jsonData = await exportDatasetAsJSON(2);
      const filename = `dark-patterns-dataset-${dayjs().format('YYYY-MM-DD-HHmmss')}.json`;

      // Direct download from popup to avoid message size limits
      triggerFallbackDownload(jsonData, filename);
    } catch (error) {
      console.error('Export error before download:', error);
      message.error(
        `Failed to prepare dataset for export: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`,
      );
    }
  };

  const handleExportTextOnly = async () => {
    try {
      const jsonlData = await exportTextDatasetAsJSONL();
      if (!jsonlData.trim()) {
        message.warning('No patterns found to export in text dataset');
        return;
      }

      const filename = `dark-patterns-text-dataset-${dayjs().format(
        'YYYY-MM-DD-HHmmss',
      )}.jsonl`;

      // Direct download from popup to avoid message size limits
      triggerFallbackDownload(jsonlData, filename);
    } catch (error) {
      console.error('Text dataset export error:', error);
      message.error(
        `Failed to export text-only dataset: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`,
      );
    }
  };

  const handleExportBundle = async () => {
    if (entries.length === 0) {
      message.warning('No dataset entries to export');
      return;
    }

    setExportingBundle(true);
    try {
      const bundleBlob = await exportDatasetAsBundleZip();
      const filename = `dark-patterns-dataset-${dayjs().format('YYYY-MM-DD-HHmmss')}.zip`;
      const blobUrl = URL.createObjectURL(bundleBlob);

      chrome.downloads.download(
        {
          url: blobUrl,
          filename,
          saveAs: true,
        },
        () => {
          if (chrome.runtime.lastError) {
            message.error(
              `Failed to export bundle: ${chrome.runtime.lastError.message}`,
            );
          } else {
            message.success('Dataset bundle exported');
          }
          setTimeout(() => URL.revokeObjectURL(blobUrl), 1000);
        },
      );
    } catch (error) {
      console.error('Bundle export error:', error);
      message.error(
        `Failed to build dataset bundle: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`,
      );
    } finally {
      setExportingBundle(false);
    }
  };

  const handleExportUITars = async () => {
    if (entries.length === 0) {
      message.warning('No dataset entries to export');
      return;
    }

    // Check if entries have bounding boxes
    const entriesWithBbox = entries.filter((e) =>
      e.patterns.some((p) => p.bbox && p.bbox.length === 4),
    );

    if (entriesWithBbox.length === 0) {
      Modal.warning({
        title: 'No Bounding Boxes Found',
        content:
          'Your dataset entries do not have bounding box annotations. GPT-4o needs to detect and return bbox coordinates for each pattern. Please re-analyze pages to get bounding boxes.',
      });
      return;
    }

    setExportingBundle(true);
    try {
      const uitarsBlob = await exportForUITarsFineTuning();
      const filename = `ui-tars-training-dataset-${dayjs().format('YYYY-MM-DD-HHmmss')}.zip`;
      const blobUrl = URL.createObjectURL(uitarsBlob);

      chrome.downloads.download(
        {
          url: blobUrl,
          filename,
          saveAs: true,
        },
        () => {
          if (chrome.runtime.lastError) {
            message.error(
              `Failed to export UI-TARS dataset: ${chrome.runtime.lastError.message}`,
            );
          } else {
            message.success(
              `UI-TARS training dataset exported (${entriesWithBbox.length} images with annotations)`,
            );
          }
          setTimeout(() => URL.revokeObjectURL(blobUrl), 1000);
        },
      );
    } catch (error) {
      console.error('UI-TARS export error:', error);
      message.error(
        `Failed to export UI-TARS dataset: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`,
      );
    } finally {
      setExportingBundle(false);
    }
  };

  const handleClear = () => {
    Modal.confirm({
      title: 'Clear All Entries',
      content:
        'Are you sure you want to delete all dataset entries? This cannot be undone.',
      onOk: async () => {
        try {
          await clearDatasetEntries();
          message.success('All entries cleared');
          await loadEntries();
        } catch (error) {
          message.error('Failed to clear entries');
        }
      },
    });
  };

  const handleDelete = async (id: string) => {
    try {
      await deleteDatasetEntry(id);
      message.success('Entry deleted');
      await loadEntries();
    } catch (error) {
      message.error('Failed to delete entry');
    }
  };

  // Export COCO format
  const handleExportCOCO = async () => {
    setExportingBundle(true);
    try {
      const blob = await exportAsCOCO();
      const filename = `dark-patterns-coco-${dayjs().format('YYYY-MM-DD-HHmmss')}.zip`;
      const blobUrl = URL.createObjectURL(blob);
      chrome.downloads.download(
        { url: blobUrl, filename, saveAs: true },
        () => {
          if (chrome.runtime.lastError) {
            message.error(
              `Failed to export COCO: ${chrome.runtime.lastError.message}`,
            );
          } else {
            message.success('COCO format dataset exported!');
          }
          setTimeout(() => URL.revokeObjectURL(blobUrl), 1000);
        },
      );
    } catch (error) {
      message.error(
        `Failed to export COCO: ${error instanceof Error ? error.message : 'Unknown error'}`,
      );
    } finally {
      setExportingBundle(false);
    }
  };

  // Export YOLO format
  const handleExportYOLO = async () => {
    setExportingBundle(true);
    try {
      const blob = await exportAsYOLO();
      const filename = `dark-patterns-yolo-${dayjs().format('YYYY-MM-DD-HHmmss')}.zip`;
      const blobUrl = URL.createObjectURL(blob);
      chrome.downloads.download(
        { url: blobUrl, filename, saveAs: true },
        () => {
          if (chrome.runtime.lastError) {
            message.error(
              `Failed to export YOLO: ${chrome.runtime.lastError.message}`,
            );
          } else {
            message.success('YOLO format dataset exported!');
          }
          setTimeout(() => URL.revokeObjectURL(blobUrl), 1000);
        },
      );
    } catch (error) {
      message.error(
        `Failed to export YOLO: ${error instanceof Error ? error.message : 'Unknown error'}`,
      );
    } finally {
      setExportingBundle(false);
    }
  };

  // Export annotated images
  const handleExportAnnotatedImages = async () => {
    setExportingBundle(true);
    try {
      const blob = await exportAnnotatedImages();
      const filename = `dark-patterns-annotated-${dayjs().format('YYYY-MM-DD-HHmmss')}.zip`;
      const blobUrl = URL.createObjectURL(blob);
      chrome.downloads.download(
        { url: blobUrl, filename, saveAs: true },
        () => {
          if (chrome.runtime.lastError) {
            message.error(
              `Failed to export: ${chrome.runtime.lastError.message}`,
            );
          } else {
            message.success('Annotated images exported!');
          }
          setTimeout(() => URL.revokeObjectURL(blobUrl), 1000);
        },
      );
    } catch (error) {
      message.error(
        `Failed to export: ${error instanceof Error ? error.message : 'Unknown error'}`,
      );
    } finally {
      setExportingBundle(false);
    }
  };

  // Open bbox editor for an entry
  const handleEditBboxes = (entry: DatasetEntry) => {
    if (!entry.screenshot) {
      message.error('No screenshot available for this entry');
      return;
    }
    setEditingEntry(entry);
    setShowBboxEditor(true);
  };

  // Save bbox edits
  const handleSaveBboxEdits = async (patterns: DarkPattern[]) => {
    if (!editingEntry) return;

    try {
      // Re-crop images for updated patterns
      const patternsWithCrops = await Promise.all(
        patterns.map(async (p) => {
          if (p.bbox && p.bbox.length === 4 && editingEntry.screenshot) {
            try {
              const croppedImage = await cropImageFromBbox(
                editingEntry.screenshot,
                p.bbox,
              );
              return { ...p, croppedImage };
            } catch {
              return p;
            }
          }
          return p;
        }),
      );

      const updatedEntry: DatasetEntry = {
        ...editingEntry,
        patterns: patternsWithCrops,
      };

      await storeDatasetEntry(updatedEntry);
      message.success('Bounding boxes updated!');
      setShowBboxEditor(false);
      setEditingEntry(null);
      await loadEntries();
    } catch (error) {
      message.error('Failed to save edits');
    }
  };

  const getSeverityColor = (severity: string) => {
    switch (severity) {
      case 'critical':
        return 'red';
      case 'high':
        return 'orange';
      case 'medium':
        return 'gold';
      case 'low':
        return 'blue';
      default:
        return 'default';
    }
  };

  const patternBreakdown = Object.entries(
    statistics.categoryBreakdown || {},
  ).sort((a, b) => b[1] - a[1]);

  const patternFilterOptions = [
    { label: 'All Patterns', value: 'ALL' },
    ...patternBreakdown.map(([type]) => ({ label: type, value: type })),
  ];

  return (
    <div className="dataset-collection-container">
      {!readyState.isReady && readyState.errorMessage && (
        <Alert
          message="Configuration Required"
          description={readyState.errorMessage}
          type="warning"
          showIcon
          style={{ marginBottom: 16 }}
          action={
            <Button size="small" onClick={() => window.location.reload()}>
              Refresh
            </Button>
          }
        />
      )}

      <div className="dataset-header">
        <Row gutter={16} style={{ marginBottom: 16 }}>
          <Col span={6}>
            <Statistic
              title="Websites Scanned"
              value={statistics.totalEntries}
              prefix={<FileTextOutlined />}
            />
          </Col>
          <Col span={6}>
            <Statistic
              title="Patterns Found"
              value={statistics.totalPatterns}
              prefix={<WarningOutlined />}
            />
          </Col>
          <Col span={6}>
            <Statistic
              title="Prevalence Rate"
              value={statistics.prevalenceRate}
              suffix="%"
              precision={1}
              prefix={<CheckCircleOutlined />}
            />
          </Col>
          <Col span={6}>
            <Statistic
              title="PK E-commerce"
              value={statistics.pakistaniSitesScanned}
            />
          </Col>
        </Row>

        <Row gutter={16} style={{ marginBottom: 12 }}>
          <Col span={12}>
            <Card
              size="small"
              title="Pattern Counts"
              bodyStyle={{ padding: 12 }}
            >
              {patternBreakdown.length === 0 ? (
                <Text type="secondary">No patterns detected yet.</Text>
              ) : (
                <Space wrap>
                  {patternBreakdown.map(([type, count]) => (
                    <Tag key={type} color="blue">
                      {type}: {count}
                    </Tag>
                  ))}
                </Space>
              )}
            </Card>
          </Col>
          <Col span={12}>
            <Card
              size="small"
              title="Filter by Pattern"
              bodyStyle={{ padding: 12 }}
            >
              <Select
                style={{ minWidth: 240 }}
                options={patternFilterOptions}
                value={filterPattern}
                onChange={(v) => setFilterPattern(v)}
              />
            </Card>
          </Col>
        </Row>

        <Space wrap>
          <Button
            type="primary"
            icon={<PlayCircleOutlined />}
            onClick={analyzeCurrentPage}
            loading={analyzing}
            disabled={!readyState.isReady}
          >
            Analyze Current Page
          </Button>
          <Button
            icon={<FileTextOutlined />}
            onClick={handleBatchProcess}
            disabled={isProcessingQueue || !readyState.isReady}
          >
            Batch Process (Manual URLs)
          </Button>
          <Button
            icon={<FileTextOutlined />}
            onClick={handleAutoDiscoverLinks}
            disabled={
              isProcessingQueue || isRecursiveCrawling || !readyState.isReady
            }
          >
            {isRecursiveCrawling
              ? 'üï∑Ô∏è Crawling Website...'
              : 'Batch Process (Auto Crawl)'}
          </Button>
          <Button
            icon={<DownloadOutlined />}
            onClick={handleExport}
            disabled={entries.length === 0}
          >
            Export JSON (Full)
          </Button>
          <Button
            icon={<DownloadOutlined />}
            onClick={handleExportTextOnly}
            disabled={entries.length === 0}
          >
            Export Text Dataset (JSONL)
          </Button>
          <Button
            icon={<DownloadOutlined />}
            onClick={handleExportBundle}
            loading={exportingBundle}
            disabled={entries.length === 0}
          >
            Export Bundle (ZIP)
          </Button>
          <Button
            type="primary"
            icon={<DownloadOutlined />}
            onClick={handleExportUITars}
            loading={exportingBundle}
            disabled={entries.length === 0}
            style={{ backgroundColor: '#52c41a', borderColor: '#52c41a' }}
          >
            Export UI-TARS Format
          </Button>
          <Button
            icon={<DownloadOutlined />}
            onClick={handleExportCOCO}
            loading={exportingBundle}
            disabled={entries.length === 0}
            style={{
              backgroundColor: '#722ed1',
              borderColor: '#722ed1',
              color: '#fff',
            }}
          >
            Export COCO Format
          </Button>
          <Button
            icon={<DownloadOutlined />}
            onClick={handleExportYOLO}
            loading={exportingBundle}
            disabled={entries.length === 0}
            style={{
              backgroundColor: '#eb2f96',
              borderColor: '#eb2f96',
              color: '#fff',
            }}
          >
            Export YOLO Format
          </Button>
          <Button
            icon={<EyeOutlined />}
            onClick={handleExportAnnotatedImages}
            loading={exportingBundle}
            disabled={entries.length === 0}
          >
            Export Annotated Images
          </Button>
          <Button
            danger
            icon={<DeleteOutlined />}
            onClick={handleClear}
            disabled={entries.length === 0}
          >
            Clear All
          </Button>
        </Space>
      </div>

      {crawlProgress && (
        <Card style={{ marginBottom: 16, border: '2px solid #1890ff' }}>
          <Space direction="vertical" style={{ width: '100%' }}>
            <Text strong style={{ fontSize: '16px' }}>
              üï∑Ô∏è Full Website Crawl in Progress
            </Text>
            <Row gutter={16}>
              <Col span={6}>
                <Statistic
                  title="Discovered"
                  value={crawlProgress.discovered}
                  valueStyle={{ color: '#1890ff' }}
                />
              </Col>
              <Col span={6}>
                <Statistic
                  title="Visited"
                  value={crawlProgress.visited}
                  valueStyle={{ color: '#52c41a' }}
                />
              </Col>
              <Col span={6}>
                <Statistic
                  title="In Queue"
                  value={crawlProgress.queue}
                  valueStyle={{ color: '#faad14' }}
                />
              </Col>
            </Row>
            <Text
              type="secondary"
              style={{ fontSize: '12px', display: 'block', marginTop: 8 }}
            >
              <strong>Current:</strong>{' '}
              {crawlProgress.currentUrl.length > 80
                ? `${crawlProgress.currentUrl.substring(0, 80)}...`
                : crawlProgress.currentUrl}
            </Text>
            <Text
              type="secondary"
              style={{ fontSize: '11px', display: 'block', marginTop: 4 }}
            >
              This may take 10-30 minutes. Please keep this window open.
            </Text>
          </Space>
        </Card>
      )}

      {progress && (
        <Card style={{ marginBottom: 16 }}>
          <Progress
            percent={Math.round((progress.current / progress.total) * 100)}
            status="active"
          />
          <Space direction="vertical" style={{ width: '100%', marginTop: 8 }}>
            <Text strong>
              Processing {progress.current} of {progress.total}
            </Text>
            <Text
              type="secondary"
              style={{ fontSize: '12px', display: 'block' }}
            >
              {progress.status}
            </Text>
            <Text
              type="secondary"
              style={{ fontSize: '12px', display: 'block' }}
            >
              {progress.url}
            </Text>
          </Space>
        </Card>
      )}

      {entries.length === 0 ? (
        <Empty
          description="No dataset entries yet. Click 'Analyze Current Page' to start collecting data."
          image={Empty.PRESENTED_IMAGE_SIMPLE}
        />
      ) : (
        <List
          dataSource={filteredEntries}
          renderItem={(entry) => (
            <List.Item>
              <Card style={{ width: '100%' }}>
                <div className="entry-header">
                  <div>
                    <Text strong>
                      {entry.metadata?.pageTitle || 'Untitled'}
                    </Text>
                    <br />
                    <Text type="secondary" style={{ fontSize: '12px' }}>
                      {entry.url}
                    </Text>
                    <br />
                    <Text type="secondary" style={{ fontSize: '12px' }}>
                      {dayjs(entry.timestamp).format('YYYY-MM-DD HH:mm:ss')}
                    </Text>
                  </div>
                  <Space>
                    <Button
                      danger
                      size="small"
                      icon={<DeleteOutlined />}
                      onClick={() => handleDelete(entry.id)}
                    >
                      Delete
                    </Button>
                  </Space>
                </div>

                {entry.patterns.length === 0 ? (
                  <Tag color="green">No dark patterns detected</Tag>
                ) : (
                  <div className="patterns-list">
                    {entry.patterns.map((pattern, idx) => (
                      <Card
                        key={idx}
                        size="small"
                        style={{ marginTop: 8 }}
                        title={
                          <Space>
                            <Tag color={getSeverityColor(pattern.severity)}>
                              {pattern.severity.toUpperCase()}
                            </Tag>
                            <Text strong>{pattern.type}</Text>
                          </Space>
                        }
                      >
                        {/* Image display removed for Text-First strategy */}

                        <Paragraph style={{ margin: 0 }}>
                          <Text strong>Location: </Text>
                          {pattern.location}
                        </Paragraph>
                        <Paragraph style={{ margin: '4px 0' }}>
                          <Text strong>Description: </Text>
                          {pattern.description}
                        </Paragraph>
                        <Paragraph style={{ margin: 0 }}>
                          <Text strong>Evidence: </Text>
                          <Text code>{pattern.evidence}</Text>
                        </Paragraph>
                        {pattern.confidence !== undefined && (
                          <Text
                            type="secondary"
                            style={{ fontSize: '12px', display: 'block' }}
                          >
                            Confidence: {(pattern.confidence * 100).toFixed(0)}%
                          </Text>
                        )}
                        {pattern.bbox && pattern.bbox.length === 4 && (
                          <Text
                            type="secondary"
                            style={{
                              fontSize: '12px',
                              display: 'block',
                              marginTop: 4,
                            }}
                          >
                            Bounding Box: [{pattern.bbox.join(', ')}]
                          </Text>
                        )}
                      </Card>
                    ))}
                  </div>
                )}
              </Card>
            </List.Item>
          )}
        />
      )}
      {showBboxEditor && editingEntry && editingEntry.screenshot && (
        <Modal
          title="Edit Bounding Boxes"
          open={true}
          onCancel={() => {
            setShowBboxEditor(false);
            setEditingEntry(null);
          }}
          footer={null}
          width="90%"
          style={{ top: 20 }}
          bodyStyle={{ height: '80vh', padding: 0 }}
          destroyOnClose
        >
          <BboxEditor
            screenshot={editingEntry.screenshot}
            patterns={editingEntry.patterns}
            onSave={handleSaveBboxEdits}
            onCancel={() => {
              setShowBboxEditor(false);
              setEditingEntry(null);
            }}
          />
        </Modal>
      )}
    </div>
  );
}
